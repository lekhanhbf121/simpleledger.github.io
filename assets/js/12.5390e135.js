(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{207:function(e,t,a){e.exports=a.p+"assets/img/bfp-fig-1.27a6fd68.png"},243:function(e,t,a){"use strict";a.r(t);var i=a(2),o=Object(i.a)({},(function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[i("h1",{attrs:{id:"bitcoin-files-protocol-specification"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#bitcoin-files-protocol-specification"}},[e._v("#")]),e._v(" Bitcoin Files Protocol Specification")]),e._v(" "),i("h3",{attrs:{id:"specification-version-0-5"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#specification-version-0-5"}},[e._v("#")]),e._v(" Specification version: 0.5")]),e._v(" "),i("h3",{attrs:{id:"date-orginally-published-september-21-2018"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#date-orginally-published-september-21-2018"}},[e._v("#")]),e._v(" Date orginally published: September 21, 2018")]),e._v(" "),i("h3",{attrs:{id:"uri-bitcoinfiles-com"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#uri-bitcoinfiles-com"}},[e._v("#")]),e._v(" URI: "),i("a",{attrs:{href:"https://bitcoinfiles.com",target:"_blank",rel:"noopener noreferrer"}},[e._v("bitcoinfiles.com"),i("OutboundLink")],1)]),e._v(" "),i("h2",{attrs:{id:"authors"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#authors"}},[e._v("#")]),e._v(" Authors")]),e._v(" "),i("p",[e._v("James Cramer, Attila Aros, hapticpilot")]),e._v(" "),i("h2",{attrs:{id:"acknowledgements"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#acknowledgements"}},[e._v("#")]),e._v(" Acknowledgements")]),e._v(" "),i("p",[e._v("Mark Lundeberg, Jonald Fyookball, Calin Culianu, Adam Gall for various suggestions and considerations")]),e._v(" "),i("h2",{attrs:{id:"_1-introduction"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_1-introduction"}},[e._v("#")]),e._v(" 1. Introduction")]),e._v(" "),i("p",[e._v("The following presents a simple protocol for adding files to the Bitcoin Cash blockchain. The protocol also allows for creating immutable URIs (Uniform Resource Identifiers) pointing to off-chain data storage systems. The motivation for this protocol was driven by the lack of reliable and anonymous file upload and storage systems, which have a simple API.")]),e._v(" "),i("p",[e._v("The original purpose of this protocol was to facilitate the uploading of JSON documents associated with a SLP token's GENESIS transaction. BFP is a separate protocol from SLP Tokens, but its design uses a DAG (Directed Acyclic Graph) to link file chunks and metadata together in multiple transactions so in a way it is similar to SLP tokens.")]),e._v(" "),i("h2",{attrs:{id:"_2-protocol"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-protocol"}},[e._v("#")]),e._v(" 2. Protocol")]),e._v(" "),i("p",[e._v("This protocol specification describes the requirements for handling the storage of URIs and complete files within the Bitcoin Cash blockchain.")]),e._v(" "),i("h3",{attrs:{id:"_2-1-bfp-types"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-bfp-types"}},[e._v("#")]),e._v(" 2.1 BFP Types")]),e._v(" "),i("p",[e._v("Unique BFP message types are used to represent different constructs in the BFP protocol. In any BFP OP_RETURN message, the BFP message type is represented by the required field named "),i("code",[e._v("bfp_msg_type")]),e._v(". There are currently three types of BFP constructs. They are:")]),e._v(" "),i("ul",[i("li",[i("code",[e._v("bfp_msg_type = 0x01")]),e._v(": A file (OP_RETURN storage).")]),e._v(" "),i("li",[i("code",[e._v("bfp_msg_type = 0x02")]),e._v(": A file (P2SH storage).")]),e._v(" "),i("li",[i("code",[e._v("bfp_msg_type = 0x03")]),e._v(": A folder.")])]),e._v(" "),i("h3",{attrs:{id:"_2-2-a-file-bfp-message-type-0x01"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-a-file-bfp-message-type-0x01"}},[e._v("#")]),e._v(" 2.2 A File (BFP Message Type = 0x01)")]),e._v(" "),i("p",[e._v("Files are uploaded to the blockchain in a series of data chunks encapsulated within OP_RETURN messages located at vout=0 (i.e. the first output) in each data chunk's respective transaction.  The file chunks reference each other using the vout=1 output as a pointer to the location of the next data chunk.  The file can be shared with anyone by sharing the transaction hash of the last uploaded data chunk containing optional file metadata.  The following illustration shows an example two-part file upload using this protocol.")]),e._v(" "),i("p",[i("img",{attrs:{src:a(207),alt:"bfp-fig-1"}})]),e._v(" "),i("p",[i("strong",[e._v("Figure 1: A file uploaded to the blockchain using an initial funding transaction followed by two data chunks transactions.  Data stored within OP_RETURN space is highlighted in yellow.")])]),e._v(" "),i("p",[e._v("The transaction hash belonging to the final transaction made in the series of uploaded data chunks represents the file's physical location in the blockchain data structure.  This final transaction contains a special set of file metadata parameters including the number of chunks associated with the file which is required for downloading the file.")]),e._v(" "),i("p",[e._v("It is recommended that an initial funding transaction be created (as shown in the above figure) to cover the costs of all subsequent transactions.  The benefits of using an initial funding transaction include simplified coin management and reduced overall upload cost since each data chunk's transaction only has 1 input.")]),e._v(" "),i("h4",{attrs:{id:"_2-2-1-rules-for-on-chain-file-uploads"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-1-rules-for-on-chain-file-uploads"}},[e._v("#")]),e._v(" 2.2.1 Rules for on-chain file uploads")]),e._v(" "),i("ol",[i("li",[i("p",[i("strong",[e._v("Data Chunk Order:")]),e._v(" Data chunks shall be ordered in the order that the transactions are signed.  This means the first chunk of the file represents the first part of the file and is signed first.  The last data chunk of the file is signed last and may be placed within the final metadata transaction if there is sufficient room.")])]),e._v(" "),i("li",[i("p",[i("strong",[e._v("Metadata OP_RETURN Message:")]),e._v(" The final signed transaction for a file upload must contain an OP_RETURN output message located at output index 0 (i.e., vout:0).  The required format for this final message is:")]),e._v(" "),i("ul",[i("li",[i("code",[e._v("OP_RETURN <lokad_id_int = 'BFP\\x00'> <bfp_msg_type = 0x01> <chunk_count_int> <filename_utf8*> <file_extension_utf8*> <file_byte_count_int*> <file_sha256_bytes*> <previous_file_sha256_bytes*> <file_uri_utf8*> <chunk_X_data_bytes*>")])]),e._v(" "),i("li",[e._v("If the file includes only 1 data chunk "),i("em",[e._v("AND")]),e._v(" that data chunk can fit within the metadata transaction then only a single transaction is required for the upload.")]),e._v(" "),i("li",[e._v("If the file includes multiple data chunks a Data Chunk OP_RETURN transaction described below shall be used to facilitate uploading of the data chunks.")]),e._v(" "),i("li",[e._v("NOTE: The "),i("code",[e._v("previous_file_sha256_bytes")]),e._v(" field can be filled in with either a previous file hash or a previous BFP file transaction hash.  This is left up to the application developer.")])])]),e._v(" "),i("li",[i("p",[i("strong",[e._v("Data Chunk OP_RETURN Message:")]),e._v(" For any non-final data chunk transaction (meaning not the Metadata transaction) output index 0 (i.e., vout: 0) shall contain the OP_RETURN message with the following format:")]),e._v(" "),i("ul",[i("li",[i("code",[e._v("OP_RETURN <chunk_X_data_bytes>")])])])]),e._v(" "),i("li",[i("p",[i("strong",[e._v("Data Chunk Transaction Baton:")]),e._v(" For any non-final data chunk transaction a baton shall be used as a reference pointer to the file's next data chunk or metadata. Output index 1 (i.e., vout: 1) shall contain the UTXO dust that shall be spent in the next data chunk or metadata transaction.  The baton shall be spent as the first input (i.e., vin: 0) of the next data chunk or metadata.")])])]),e._v(" "),i("h4",{attrs:{id:"_2-2-2-procedure-for-downloading-on-chain-files"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-2-procedure-for-downloading-on-chain-files"}},[e._v("#")]),e._v(" 2.2.2 Procedure for downloading on-chain files")]),e._v(" "),i("p",[e._v("Files are located on the blockchain using the hash of the transaction containing the file's Metadata OP_RETURN message. In order to download the full file content the software implementation simply needs to follow the following steps:")]),e._v(" "),i("ol",[i("li",[e._v("Download the file's metadata transaction")]),e._v(" "),i("li",[e._v("Parse for Metadata OP_RETURN message located at the first output (i.e., vout:0) within that transaction")]),e._v(" "),i("li",[e._v("If "),i("code",[e._v("chunk_count")]),e._v(" = 1 "),i("em",[e._v("and")]),e._v(" a data chunk is provided within the metadata message then the procedure is complete and the file can be reconstructed from the data chunk contents.")]),e._v(" "),i("li",[e._v("If "),i("code",[e._v("chunk_count")]),e._v(" = 0 the file is not being stored on-chain.  Even if "),i("code",[e._v("chunk_data")]),e._v(" is not empty the data chunk should be treated as if it isn't there by an implementation.  An off-chain only file can be stored if "),i("code",[e._v("chunk_count")]),e._v(" = 0 "),i("em",[e._v("and")]),e._v(" "),i("code",[e._v("file_uri_utf8")]),e._v(" is not empty; this may be valuable for applications where having immutable store of file metadata has value.")]),e._v(" "),i("li",[e._v('If there are more chunks that need to be downloaded then use the transaction hash specified at vin:0 to find the next data chunk and parse data chunk transactions using the "Data Chunk OP_RETURN" format.')]),e._v(" "),i("li",[e._v("Repeat step 4 until all of the data chunks have been parsed.")]),e._v(" "),i("li",[e._v("Assemble the file from the data chunks using the first signed = first chunk rule.")])]),e._v(" "),i("h4",{attrs:{id:"_2-2-3-procedure-for-downloading-off-chain-files"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-3-procedure-for-downloading-off-chain-files"}},[e._v("#")]),e._v(" 2.2.3 Procedure for downloading off-chain files")]),e._v(" "),i("p",[e._v("Cases where "),i("code",[e._v("file_uri_utf8")]),e._v(" is provided to an off-chain storage location implementations may elect how to handle downloads.  Use of IPFS is recommended and additional considerations for using IPFS have been provided in Appendix A.")]),e._v(" "),i("h3",{attrs:{id:"_2-3-a-file-bfp-message-type-0x02"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-a-file-bfp-message-type-0x02"}},[e._v("#")]),e._v(" 2.3 A File (BFP Message Type = 0x02)")]),e._v(" "),i("p",[e._v("Larger files (~100KB) may be stored on-chain using "),i("code",[e._v("bfp_msg_type")]),e._v(" 0x02. This type is nearly identical to the 0x01 file type, however, files are uploaded to the blockchain in a series of data chunks encapsulated within the spending of P2SH outputs within "),i("code",[e._v("scriptSig")]),e._v(" located at vin=0 (i.e. the first input index) for each data chunk's respective transaction.  The file chunks reference each other using the vout=1 output as a pointer to the location of the next data chunk.  The file can be shared with anyone by sharing the transaction hash of the last uploaded data chunk containing optional file metadata.")]),e._v(" "),i("p",[e._v("Redeem script shall have the following format:\n"),i("code",[e._v("OP_DROP ... OP_DROP <PubKey> OP_CHECKSIG")])]),e._v(" "),i("p",[e._v("Unlocking script shall have the following format:\n"),i("code",[e._v("<signature> <data> ... <data> <redeem script>")])]),e._v(" "),i("p",[e._v("Where "),i("code",[e._v("...")]),e._v(" may represent "),i("code",[e._v("OP_DROP")]),e._v(" and "),i("code",[e._v("<data>")]),e._v("repeated any number of valid times. The data items are pushed in approximately 520 byte pieces and shall be concatenated together to produce the whole data chunk associated with the transaction.")]),e._v(" "),i("h3",{attrs:{id:"_2-4-folders-bfp-message-type-0x03"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-folders-bfp-message-type-0x03"}},[e._v("#")]),e._v(" 2.4 Folders (BFP Message Type = 0x03)")]),e._v(" "),i("p",[e._v("A folder message type stores one or more transaction hashes pointing to files and other folders.  This type of message simply provides a list of transaction hashes.")]),e._v(" "),i("h4",{attrs:{id:"_2-4-1-rules-for-creating-folders"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-1-rules-for-creating-folders"}},[e._v("#")]),e._v(" 2.4.1 Rules for creating folders")]),e._v(" "),i("ol",[i("li",[i("p",[i("strong",[e._v("Metadata Transaction OP_RETURN Message:")]),e._v(" A single transaction containing an OP_RETURN message at output index 0 (i.e., vout:0).  The required format for a new folder is:")]),e._v(" "),i("ul",[i("li",[i("p",[i("code",[e._v("OP_RETURN <lokad_id_int = 'BFP\\x00'> <bfp_msg_type = 0x02> <list_page_count> <folder_name*> <folder_description*> <txid_0_int> ... <txid_i_int*> ... <txid_n_int*>")])]),e._v(" "),i("p",[e._v("Where "),i("code",[e._v("<txid_0_int>")]),e._v("  and "),i("code",[e._v("<txid_x_int*>")]),e._v(" represent a transaction hash pointing to another BFP folder or BFP file.  At least one transaction hash is required and additional optional transaction hashes may be provided.")])])])]),e._v(" "),i("li",[i("p",[i("strong",[e._v("List Page OP_RETURN Message:")]),e._v(" An infinite number of BFP files and folders can be referenced by a BFP folder by using a List Page OP_RETURN Message.  The number of list pages should be specified within the Metadata Transaction OP_RETURN and needs to be greater than 1 to indicate use of List Pages.  The required format for a list page message is:")]),e._v(" "),i("ul",[i("li",[i("code",[e._v("OP_RETURN <txid_0_int> ... <txid_i_int*> ... <txid_n_int*>")])])])]),e._v(" "),i("li",[i("p",[i("strong",[e._v("List Page Baton:")]),e._v("  For any list page transaction a baton is used to create a reference pointer from a folder Metadata transaction to a List Page transaction.  Output index 1 (i.e., vout: 1) shall contain the UTXO dust that shall be spent in the next transaction as the first input (i.e., vin: 0) to create the valid reference.  The next transaction after a List Page transaction can be either another List Page transaction "),i("em",[e._v("OR")]),e._v(" at the folder's Metadata transaction.")])])]),e._v(" "),i("h4",{attrs:{id:"_2-4-2-procedures-for-discovering-files-within-a-folder"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-2-procedures-for-discovering-files-within-a-folder"}},[e._v("#")]),e._v(" 2.4.2 Procedures for discovering files within a folder")]),e._v(" "),i("p",[e._v("The rules for determining what files and folders are contained within in a folder are simple.  An implementation shall parse the Metadata OP_RETURN message and any upstream List Page OP_RETURN message transactions using the specified format for the Metadata and List Page OP_RETURN messages.")]),e._v(" "),i("h2",{attrs:{id:"_3-op-return-syntax-and-format-requirements"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_3-op-return-syntax-and-format-requirements"}},[e._v("#")]),e._v(" 3. OP_RETURN Syntax and Format Requirements")]),e._v(" "),i("ol",[i("li",[e._v("Data fields are represented using the field's name within angle brackets (i.e.,  "),i("code",[e._v("<some_field_name>")]),e._v(" )")]),e._v(" "),i("li",[e._v("Optional fields are indicated using "),i("code",[e._v("*")]),e._v(" at the end of the field's name, and can be left empty using the push code "),i("code",[e._v("0x4c 0x00")]),e._v(", or "),i("code",[e._v("0x4d 0x00 0x00")]),e._v(", or "),i("code",[e._v("0x4e 0x00 0x00 0x00 0x00")]),e._v(".")]),e._v(" "),i("li",[e._v("Data push opcodes are not presented above. For each field an appropriate data push code shall be utilized.\n"),i("ul",[i("li",[e._v("Only opcodes "),i("code",[e._v("0x01")]),e._v(" to "),i("code",[e._v("0x4e")]),e._v(" are permitted (after OP_RETURN). Note this means that not all push opcodes are allowed -- it is forbidden to use the empty-push opcode "),i("code",[e._v("0x00")]),e._v(" ("),i("code",[e._v("OP_0")]),e._v(") or 1-byte literal push opcodes "),i("code",[e._v("0x4f")]),e._v("-"),i("code",[e._v("0x60")]),e._v(" ("),i("code",[e._v("OP_1")]),e._v(" through "),i("code",[e._v("OP_16")]),e._v(" and "),i("code",[e._v("OP_1NEGATE")]),e._v(") anywhere in the OP_RETURN. For example, it is invalid to use "),i("code",[e._v("0x58")]),e._v(" to push the number '8' in the 1-byte "),i("code",[e._v("chunk_count_int")]),e._v(" field of the Type 0x01 file transaction message, even though in normal bitcoin script the opcode "),i("code",[e._v("0x58")]),e._v(" is effectively equivalent to "),i("code",[e._v("0x01 0x08")]),e._v("  (push ["),i("code",[e._v("0x08")]),e._v("]). For this reason some standard bitcoin script decompilers, that treat all push opcodes on equal footing, must not be used for parsing BFP transactions.")]),e._v(" "),i("li",[e._v("Bitcoin script allows a given byte array to be pushed in various ways, and we allow this in BFP as well. For example, it is valid to push a 4-byte chunk (like the Lokad ID) in four different ways: "),i("code",[e._v("0x04 [chunk]")]),e._v(", "),i("code",[e._v("0x4c 0x04 [chunk]")]),e._v(", "),i("code",[e._v("0x4d 0x04 0x00 [chunk]")]),e._v(", or "),i("code",[e._v("0x4e 0x04 0x00 0x00 0x00 [chunk]")]),e._v(".")])])]),e._v(" "),i("li",[e._v("The Lokad Terab id for BFP is "),i("code",[e._v("0x00504642")]),e._v(" which results in the string literal "),i("code",[e._v("BFP\\x00")]),e._v(" when pushed onto the stack using little-endian byte ordering.  More information about Lokad Terab project identifiers can be found "),i("a",{attrs:{href:"https://github.com/Lokad/Terab/blob/master/spec/opreturn-prefix-guideline.md",target:"_blank",rel:"noopener noreferrer"}},[e._v("on GitHub"),i("OutboundLink")],1),e._v(".")]),e._v(" "),i("li",[e._v("Endianness: All data pushes, other than the Lokad protocol identifier, shall be pushed to the Script stack using big-endian data byte ordering.")]),e._v(" "),i("li",[e._v("The data encoding for each variable is included as the final part of the variable name.")])]),e._v(" "),i("h2",{attrs:{id:"_4-bitcoinfile-uri"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_4-bitcoinfile-uri"}},[e._v("#")]),e._v(" 4. Bitcoinfile URI")]),e._v(" "),i("p",[e._v('This part of the specification is not a protocol rule and is only a recommendation for an improved user experience.  It is recommended that a prefix of "bitcoinfile:" be used for the transaction hash/id representing either on-chain or off-chain file.  In the future the concept of folders can be added to this protocol and the prefix of "bitcoinfiles:" should be used.')]),e._v(" "),i("p",[e._v("For example:")]),e._v(" "),i("p",[i("code",[e._v("bitcoinfile:<txid-of-a-file>")])]),e._v(" "),i("p",[i("code",[e._v("bitcoinfiles:<txid-of-a-folder>")])]),e._v(" "),i("p",[e._v("The usage of a transaction id prefix shall have no impact on the protocol rules, and implementations should completely ignore the prefix if it is provided by the user.  Only the transaction hash/id matters when determining the content of a BFP message.")]),e._v(" "),i("h2",{attrs:{id:"_5-other-considerations"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_5-other-considerations"}},[e._v("#")]),e._v(" 5. Other Considerations")]),e._v(" "),i("ol",[i("li",[e._v("Network rules currently limit the number of chained transactions to 25 per block, this limits the data throughput of this protocol to slightly more than 5kB files.  Implementations will need consider the number of chained transactions a UTXO may already has before creating a file upload.  For example, the file upload may be limited to fewer than 25 transactions if the user has made several transactions prior to the file uploads within the same block height.")]),e._v(" "),i("li",[e._v("Set a limit for file upload sizes to encourage wise use of blockchain space")]),e._v(" "),i("li",[e._v("File data can be encrypted in a number of ways.  At this time it is recommended that the file extension field be utilized to convey the type of encryption if the native file format does not have internal mechanism for handling encryption (e.g., PDF).")]),e._v(" "),i("li",[e._v("In some cases of file record keeping having the ability to reference a previous file version's hash for informational purposes can be very useful.  For this reason the metadata field named "),i("code",[e._v("<previous_file_version_sha256_bytes*>")]),e._v(" has been provided.")])]),e._v(" "),i("h2",{attrs:{id:"_6-specification-updates"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_6-specification-updates"}},[e._v("#")]),e._v(" 6. Specification Updates")]),e._v(" "),i("ul",[i("li",[i("strong",[e._v("v0.2 - September 26, 2018")]),e._v(" "),i("ul",[i("li",[e._v("Added BFP Message Type ( "),i("code",[e._v("bfp_msg_type")]),e._v(" )")]),e._v(" "),i("li",[e._v("Added folder BFP Message Type = 0x02")]),e._v(" "),i("li",[e._v("Added file URI preferences")]),e._v(" "),i("li",[e._v("Added file encryption considerations")]),e._v(" "),i("li",[e._v("Added Appendix A - IPFS Considerations")]),e._v(" "),i("li",[e._v("Added co-authors Attila Aros and hapticpilot")])])])]),e._v(" "),i("h2",{attrs:{id:"_7-appendix-a-ipfs-usage"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_7-appendix-a-ipfs-usage"}},[e._v("#")]),e._v(" 7. Appendix A - IPFS Usage")]),e._v(" "),i("h4",{attrs:{id:"_7-1-ipfs-downloads"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_7-1-ipfs-downloads"}},[e._v("#")]),e._v(" 7.1 IPFS downloads")]),e._v(" "),i("p",[i("a",{attrs:{href:"https://ipfs.io",target:"_blank",rel:"noopener noreferrer"}},[e._v("IPFS"),i("OutboundLink")],1),e._v(" is a system for storing and distributing files. The key benefit of IPFS is decentralization and consistent addressability.  An IPFS can be used for storing files off-chain as either a cache or a more efficient means of data storage.")]),e._v(" "),i("p",[e._v("The URI location for a file stored on IPFS is uniquely determined by the file's hash (and a few other settings explained below shortly).  The OP_RETURN messages presented in Sections 2.2.1.2 and 2.4.1.1 allow for "),i("code",[e._v("<file_uri_utf8*>")]),e._v(" which should be leveraged when using IPFS URIs.")]),e._v(" "),i("ul",[i("li",[e._v("User agent "),i("em",[e._v("may")]),e._v(" choose to query an IPFS gateway of their choice after retrieving a BFP file's Metadata transaction.")])]),e._v(" "),i("p",[e._v("There are numerous public gateways available that would be suitable options for resolving IPFS URIs.")]),e._v(" "),i("p",[e._v("For example, for a IPFS file with hash "),i("code",[e._v("Qmc5gCcjYypU7y28oCALwfSvxCBskLuPKWpK4qpterKC7z")]),e._v(" the "),i("code",[e._v("<file_uri_utf8*>")]),e._v(" field should be set to something like: "),i("code",[e._v("https://gateway.ipfs.io/ipfs/Qmc5gCcjYypU7y28oCALwfSvxCBskLuPKWpK4qpterKC7z")]),e._v(", allowing a user agent to interpret this URI and download the file from an IPFS gateway.  User agent's may consider the following:")]),e._v(" "),i("ul",[i("li",[e._v("User browser agent "),i("em",[e._v("may")]),e._v(" choose to query an IPFS swarm directly instead using a pure Javascript/Browser implementation such as "),i("a",{attrs:{href:"https://github.com/ipfs/js-ipfs",target:"_blank",rel:"noopener noreferrer"}},[e._v("js-ipfs"),i("OutboundLink")],1),e._v(".")]),e._v(" "),i("li",[e._v("User agent "),i("em",[e._v("may")]),e._v(" to set a time limit for how long they are willing to wait for IPFS to resolve the content, and instead opt for retrieving the individual chunk transactions to serve their request instead.")]),e._v(" "),i("li",[e._v("If the content is not retrievable or not found on IPFS, then the user "),i("em",[e._v("may")]),e._v(" re-upload the content to IPFS after retrieving the content bytes from the transaction chunks.")])]),e._v(" "),i("p",[e._v("The next section highlights considerations for performing an upload as there are some IPFS specific flags that need to be set consistently to arrive at the same IPFS hash.")]),e._v(" "),i("h4",{attrs:{id:"_2-4-2-2-ipfs-uploads"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-2-2-ipfs-uploads"}},[e._v("#")]),e._v(" 2.4.2.2 IPFS uploads")]),e._v(" "),i("p",[e._v("IPFS hashes are uniquely determined by a few parameters, not simply the sha256 hash of the file content. This is unavoidable since IPFS provides different storage options, identifier versioning, and also needs some flexibility for the future.")]),e._v(" "),i("p",[e._v("IPFS options (which determine the IPFS hash created with "),i("code",[e._v("ipfs add -n")]),e._v(")")]),e._v(" "),i("ul",[i("li",[e._v("Chunking algorithm (--chunker option)")]),e._v(" "),i("li",[e._v("DAG format (--trickle option)")]),e._v(" "),i("li",[e._v("CID version (--cid-version option)")]),e._v(" "),i("li",[e._v("Hashing algorithm (--hash option)\n"),i("a",{attrs:{href:"https://discuss.ipfs.io/t/how-to-calculate-file-directory-hash/777/4",target:"_blank",rel:"noopener noreferrer"}},[e._v("Source"),i("OutboundLink")],1)])]),e._v(" "),i("p",[i("strong",[e._v("Defaults")])]),e._v(" "),i("p",[e._v("--chunker:  "),i("code",[e._v("size-262144")]),e._v(" (1024*256)")]),e._v(" "),i("p",[e._v("--trickle: false")]),e._v(" "),i("p",[e._v("--cid-version: CIDv0 (Starts with 'Qm...') Note: this is a "),i("a",{attrs:{href:"https://github.com/ipld/cid#versions",target:"_blank",rel:"noopener noreferrer"}},[e._v("self-describing format"),i("OutboundLink")],1),e._v(" and therefore can be uniquely determined by looking at the hash prefix")]),e._v(" "),i("p",[e._v("--hash: sha256")]),e._v(" "),i("p",[e._v("At the time of writing, the latest version of IPFS is "),i("code",[e._v("ipfs version 0.4.17")]),e._v(" and the defaults described above are accurate for this version.")]),e._v(" "),i("p",[e._v("It is "),i("em",[e._v("recommended")]),e._v(" that user agents calculate the IPFS hash for a file using "),i("code",[e._v("ipfs add -n")]),e._v(" (and the necessary parameters). This will ensure maximum compatibility for other users, in the event that the content has been garbaged collected from all live IPFS nodes and a user wishes to make the content available again under the same IPFS hash.")]),e._v(" "),i("p",[e._v("The facilite being able to easily recreate the IPFS hash, we are "),i("em",[e._v("recommending")]),e._v(" that users include additional/optional URI query params to inform clients what IPFS hashing options were used.")]),e._v(" "),i("p",[e._v("Query format example:\n"),i("code",[e._v("Qmc5gCcjYypU7y28oCALwfSvxCBskLuPKWpK4qpterKC7z?ver=<string>&chunker=<string>&trickle=<int>&hash=<string>")])]),e._v(" "),i("p",[e._v("It is "),i("em",[e._v("recommended")]),e._v(" that the user agent sets these parameters for all the command line options for "),i("code",[e._v("ipfs add -n")]),e._v(" and then provides these values  explicitly to enable others to create the precise hash.  On the other hand, the defaults are not expected to change anytime soon, therefore as long as the user is using an unmodified version of ipfs, then they should be able to easily obtain the same hash.")]),e._v(" "),i("p",[e._v("Examples:")]),e._v(" "),i("p",[e._v("Only IPFS version is defined (default and best effort to attempt to recreate hash)\n"),i("code",[e._v("Qmc5gCcjYypU7y28oCALwfSvxCBskLuPKWpK4qpterKC7z?ver=0.4.17")])]),e._v(" "),i("ul",[i("li",[e._v("ver: "),i("code",[e._v("0.4.17")]),e._v(" is the known working version of IPFS that hash was created with")])]),e._v(" "),i("p",[e._v("Just the IPFS hash is provided (default and best effort to attempt to recreate hash)\n"),i("code",[e._v("Qmc5gCcjYypU7y28oCALwfSvxCBskLuPKWpK4qpterKC7z")])]),e._v(" "),i("p",[e._v("All options explicitly defined: (will yield the same hash if all options are matching)\n"),i("code",[e._v("Qmc5gCcjYypU7y28oCALwfSvxCBskLuPKWpK4qpterKC7z?ver=0.4.17&chunker=size-262144&trickle=0&hash=sha256")])]),e._v(" "),i("ul",[i("li",[e._v("ver: "),i("code",[e._v("0.4.17")]),e._v(" is the known working version of IPFS that hash was created with")]),e._v(" "),i("li",[e._v("chunker: "),i("code",[e._v("size-262144")]),e._v(" is the default value")]),e._v(" "),i("li",[e._v("trickle: "),i("code",[e._v("0")]),e._v(" is disabled by default")]),e._v(" "),i("li",[e._v("hash: "),i("code",[e._v("sha256")]),e._v(" is the default algorithm")])]),e._v(" "),i("p",[e._v("All options explicitly defined except chunker: (will yield the same hash if all options are matching)\n"),i("code",[e._v("Qmc5gCcjYypU7y28oCALwfSvxCBskLuPKWpK4qpterKC7z?ver=0.4.17&trickle=1&hash=sha256")])]),e._v(" "),i("ul",[i("li",[e._v("ver: "),i("code",[e._v("0.4.17")]),e._v(" is the known working version of IPFS that hash was created with")]),e._v(" "),i("li",[e._v("trickle: "),i("code",[e._v("1")]),e._v(" is disabled by default")])]),e._v(" "),i("p",[e._v("The user agent can infer that "),i("code",[e._v("chunker")]),e._v(" and "),i("code",[e._v("hash")]),e._v(" should be the default values as of version 0.4.17 and to enable "),i("code",[e._v("trickle")]),e._v(".")])])}),[],!1,null,null,null);t.default=o.exports}}]);